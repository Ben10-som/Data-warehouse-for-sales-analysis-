"""
        VERSION CLAUDE code
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    OLIST ORDER GENERATOR - AWS LAMBDA                        â•‘
â•‘                          Version Ultra-CommentÃ©e                             â•‘
â•‘                                                                              â•‘
â•‘  ğŸ¯ OBJECTIF : Simuler la gÃ©nÃ©ration de commandes e-commerce en temps rÃ©el  â•‘
â•‘                conformes au dataset Olist (Kaggle)                           â•‘
â•‘                                                                              â•‘
â•‘  ğŸ“Š DATASET OLIST : 9 tables normalisÃ©es reprÃ©sentant un marketplace        â•‘
â•‘                     brÃ©silien avec 100k commandes rÃ©elles (2016-2018)       â•‘
â•‘                                                                              â•‘
â•‘  ğŸ—ï¸ ARCHITECTURE :                                                           â•‘
â•‘     Lambda (GÃ©nÃ©rateur) â†’ Kinesis Stream â†’ Firehose â†’ S3 â†’ Redshift         â•‘
â•‘                              â†“                                               â•‘
â•‘                         DynamoDB (Ã‰tat)                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                           IMPORTS STANDARDS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import boto3          # SDK AWS pour Python - permet d'interagir avec tous les services AWS
import json           # Pour sÃ©rialiser les donnÃ©es en JSON avant envoi vers Kinesis
import random         # Pour gÃ©nÃ©rer des donnÃ©es alÃ©atoires rÃ©alistes (prix, quantitÃ©s, etc.)
import uuid           # Pour gÃ©nÃ©rer des IDs uniques (order_id, customer_id)
from datetime import datetime, timedelta  # Gestion du temps virtuel de la simulation
from decimal import Decimal              # Type requis par DynamoDB pour les nombres Ã  virgule
from faker import Faker                  # Librairie pour gÃ©nÃ©rer des fausses donnÃ©es rÃ©alistes

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      INITIALISATION DES CLIENTS AWS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLIENT DYNAMODB (Base de DonnÃ©es NoSQL)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DynamoDB = Base de donnÃ©es NoSQL serverless d'AWS
# On utilise le "resource" (haut niveau) au lieu du "client" (bas niveau)
# car c'est plus simple pour les opÃ©rations CRUD classiques
#
# Dans notre architecture, DynamoDB joue 2 rÃ´les :
# 1. TABLE INVENTORY : Stocker le stock de chaque produit (product_id â†’ stock_level)
# 2. TABLE CONFIG : Stocker l'heure virtuelle de la simulation
dynamodb = boto3.resource('dynamodb')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLIENT KINESIS (Ingestion de DonnÃ©es en Temps RÃ©el)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Kinesis Data Stream = Tuyau de donnÃ©es en temps rÃ©el
# Comparable Ã  Apache Kafka, mais entiÃ¨rement gÃ©rÃ© par AWS
#
# POURQUOI KINESIS ?
# - CapacitÃ© Ã  ingÃ©rer des milliers d'Ã©vÃ©nements par seconde
# - DÃ©couple le producteur (Lambda) du consommateur (Firehose â†’ S3)
# - Permet d'ajouter d'autres consommateurs plus tard (ex: Lambda de notification)
# - Ordre garanti par clÃ© de partition (ici : order_id)
kinesis = boto3.client('kinesis')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FAKER - GÃ‰NÃ‰RATEUR DE DONNÃ‰ES FICTIVES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Faker gÃ©nÃ¨re des donnÃ©es rÃ©alistes : noms, adresses, villes, codes postaux...
# 
# 'pt_BR' = Locale BrÃ©silien (Portugais du BrÃ©sil)
# POURQUOI ? Olist est un marketplace brÃ©silien, donc :
# - Les villes doivent Ãªtre brÃ©siliennes (SÃ£o Paulo, Rio de Janeiro...)
# - Les Ã©tats doivent Ãªtre des Ã©tats brÃ©siliens (SP, RJ, MG...)
# - Les codes postaux doivent suivre le format brÃ©silien (XXXXX-XXX)
#
# Exemples de donnÃ©es gÃ©nÃ©rÃ©es :
# - fake.city() â†’ "Porto Alegre"
# - fake.state_abbr() â†’ "RS" (Rio Grande do Sul)
# - fake.postcode() â†’ "90040-060"
fake = Faker('pt_BR')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                         CONSTANTES DE CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NOM DU KINESIS DATA STREAM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# C'est le "tuyau" dans lequel on va envoyer les commandes gÃ©nÃ©rÃ©es
# Ce stream a Ã©tÃ© crÃ©Ã© manuellement dans la console AWS (Ã‰tape 3 du guide)
#
# Configuration du stream (dans la console) :
# - Mode capacitÃ© : On-demand (s'adapte automatiquement au volume)
# - RÃ©tention : 24h par dÃ©faut (peut aller jusqu'Ã  365 jours)
STREAM_NAME = 'olist-stream-v1'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TABLE DYNAMODB : INVENTAIRE DES PRODUITS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cette table contient tous les produits Olist avec leur stock actuel
#
# SCHEMA DE LA TABLE :
# - ClÃ© primaire (Partition Key) : product_id (String)
# - Attributs :
#     * stock_level (Number) : QuantitÃ© disponible en stock
#     * category (String) : CatÃ©gorie du produit (ex: "beleza_saude")
#     * price (Decimal) : Prix de vente du produit
#
# OPERATIONS EFFECTUEES :
# - Lecture : get_random_product() lit un product_id au hasard
# - Ã‰criture : DÃ©crÃ©mentation atomique du stock Ã  chaque commande
#
# MODE CAPACITE : On-demand
# - Pas besoin de provisionner de RCU/WCU (Read/Write Capacity Units)
# - AWS ajuste automatiquement selon la charge
# - Parfait pour des charges de travail imprÃ©visibles
TABLE_INVENTORY = 'Sim_Inventory'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TABLE DYNAMODB : CONFIGURATION DE LA SIMULATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cette table ne contient qu'UN SEUL enregistrement : la config globale
#
# SCHEMA :
# - ClÃ© primaire : config_key = "GLOBAL" (String)
# - Attributs :
#     * simulated_time (String ISO) : L'heure virtuelle actuelle (ex: "2018-03-15T14:30:00")
#     * speed_factor (Number) : Vitesse de la simulation (ex: 60 = 1h simulÃ©e par exÃ©cution)
#
# POURQUOI UNE HORLOGE VIRTUELLE ?
# Le dataset Olist original couvre 2016-2018. On veut simuler cette pÃ©riode
# en accÃ©lÃ©rÃ© pour gÃ©nÃ©rer des donnÃ©es rapidement.
#
# Exemple :
# - ExÃ©cution Lambda toutes les 1 minute rÃ©elle
# - speed_factor = 60 â†’ On avance de 1h virtuelle Ã  chaque exÃ©cution
# - RÃ©sultat : 24 exÃ©cutions = 1 jour simulÃ© en 24 minutes rÃ©elles
TABLE_CONFIG = 'Sim_Config'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#              CACHE MÃ‰MOIRE POUR OPTIMISER LES ACCÃˆS DYNAMODB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROBLÃˆME Ã€ RÃ‰SOUDRE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# get_random_product() doit retourner un product_id au hasard.
# Sans cache, on devrait :
# 1. Scanner toute la table DynamoDB (32k produits Olist)
# 2. Charger tous les product_id en mÃ©moire
# 3. En choisir un au hasard
#
# COÃ›TS :
# - Un scan complet coÃ»te des RCU (Read Capacity Units)
# - C'est LENT (plusieurs secondes) et CHER ($$$ sur DynamoDB)
# - Si la Lambda s'exÃ©cute toutes les minutes â†’ 1440 scans/jour !
#
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SOLUTION : CACHE EN MÃ‰MOIRE AVEC TTL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# On garde une liste de product_id en mÃ©moire dans la variable globale PRODUCT_CACHE
#
# AVANTAGES :
# - On ne scanne la table qu'UNE FOIS au dÃ©marrage de la Lambda
# - Les exÃ©cutions suivantes rÃ©utilisent le cache (gratuit, instantanÃ©)
# - Si la Lambda reste "chaude" (AWS rÃ©utilise le conteneur), le cache persiste
#
# LIMITATIONS DE CETTE APPROCHE SIMPLE :
# - Si de nouveaux produits sont ajoutÃ©s Ã  DynamoDB, le cache ne le sait pas
# - Si la Lambda "froide" redÃ©marre, il faut rescanner (mais c'est rare)
#
# AMÃ‰LIORATIONS POSSIBLES (pour production) :
# - Utiliser ElastiCache Redis pour un cache distribuÃ© entre toutes les Lambdas
# - Utiliser DynamoDB DAX (cache intÃ©grÃ© Ã  DynamoDB, ultra-rapide)
# - Mettre un TTL (Time To Live) pour rafraÃ®chir le cache toutes les X heures
#
# Pour ce projet Ã©ducatif, cette approche simple suffit largement.
PRODUCT_CACHE = []

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    FONCTIONS DE GESTION DU TEMPS VIRTUEL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_simulation_state():
    """
    ğŸ“– RÃ‰CUPÃˆRE L'Ã‰TAT ACTUEL DE LA SIMULATION DEPUIS DYNAMODB
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CONCEPT CLÃ‰ : TEMPS VIRTUEL                                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Au lieu d'utiliser l'heure rÃ©elle (datetime.now()),         â”‚
    â”‚  on utilise une "horloge virtuelle" stockÃ©e dans DynamoDB.   â”‚
    â”‚                                                               â”‚
    â”‚  Cette horloge avance selon speed_factor Ã  chaque exÃ©cution. â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ¯ POURQUOI UN TEMPS VIRTUEL ?
    
    1. SIMULATION ACCÃ‰LÃ‰RÃ‰E
       - Le dataset Olist couvre 2 ans (2016-2018)
       - GÃ©nÃ©rer 2 ans de donnÃ©es en temps rÃ©el prendrait... 2 ans !
       - Avec speed_factor=60, on simule 1 jour en ~24 minutes
    
    2. REPRODUCTIBILITÃ‰
       - On peut "rejouer" la simulation Ã  partir d'une date donnÃ©e
       - Utile pour dÃ©boguer ou tester des scÃ©narios
    
    3. COHÃ‰RENCE TEMPORELLE
       - Toutes les commandes gÃ©nÃ©rÃ©es ont un timestamp cohÃ©rent
       - Pas de "saut dans le temps" entre deux exÃ©cutions
    
    ğŸ“Š EXEMPLE DE PROGRESSION TEMPORELLE :
    
    ExÃ©cution 1 : 2018-01-01 00:00 â†’ GÃ©nÃ¨re 5 commandes â†’ Avance de 60 min
    ExÃ©cution 2 : 2018-01-01 01:00 â†’ GÃ©nÃ¨re 3 commandes â†’ Avance de 60 min
    ExÃ©cution 3 : 2018-01-01 02:00 â†’ GÃ©nÃ¨re 8 commandes â†’ Avance de 60 min
    ...
    AprÃ¨s 24 exÃ©cutions : On a simulÃ© 24 heures (1 journÃ©e complÃ¨te)
    
    ğŸ”„ RETOUR DE LA FONCTION :
    --------
    tuple: (datetime sim_time, int speed_factor)
        - sim_time : L'heure virtuelle actuelle (ex: 2018-03-15 14:30:00)
        - speed_factor : Nombre de minutes virtuelles Ã  avancer par exÃ©cution (ex: 60)
    
    ğŸ’¡ GESTION DU CAS "PREMIÃˆRE EXÃ‰CUTION" :
    --------
    Si la table Config est vide (Item non trouvÃ©), on retourne des valeurs par dÃ©faut :
    - Date de dÃ©but : 1er janvier 2018 Ã  minuit
    - Speed factor : 60 minutes par exÃ©cution
    """
    
    # Connexion Ã  la table de configuration
    table = dynamodb.Table(TABLE_CONFIG)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # LECTURE DE L'ITEM DE CONFIGURATION
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # get_item() = OpÃ©ration de lecture par clÃ© primaire (trÃ¨s rapide, 1 RCU)
    # Alternative : scan() (lent, coÃ»teux) ou query() (si on avait un sort key)
    #
    # Key={'config_key': 'GLOBAL'} â†’ On rÃ©cupÃ¨re l'unique enregistrement
    # Cette table ne contient qu'un seul item, donc pas d'ambiguÃ¯tÃ©
    resp = table.get_item(Key={'config_key': 'GLOBAL'})
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CAS 1 : AUCUNE CONFIGURATION N'EXISTE (PREMIÃˆRE EXÃ‰CUTION)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Si 'Item' n'est pas dans la rÃ©ponse, c'est que l'item n'existe pas
    # Cela peut arriver si :
    # - Le script init_inventory.py n'a pas Ã©tÃ© exÃ©cutÃ©
    # - La table Config a Ã©tÃ© vidÃ©e manuellement
    # - C'est la toute premiÃ¨re exÃ©cution aprÃ¨s crÃ©ation des tables
    if 'Item' not in resp:
        # VALEURS PAR DÃ‰FAUT
        # Date : 1er janvier 2018 Ã  minuit (dÃ©but du dataset Olist typique)
        # Speed : 60 minutes virtuelles par exÃ©cution Lambda
        # 
        # Avec EventBridge Ã  1 minute rÃ©elle â†’ 1h simulÃ©e/minute â†’ 24h/jour rÃ©el
        return datetime(2018, 1, 1), 60
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CAS 2 : CONFIGURATION EXISTANTE (EXÃ‰CUTIONS SUIVANTES)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    item = resp['Item']
    
    # â”€â”€ Extraction du temps simulÃ© â”€â”€
    # DynamoDB ne stocke pas de type datetime natif
    # On stocke en String au format ISO 8601 : "2018-03-15T14:30:00"
    # datetime.fromisoformat() convertit cette string en objet datetime Python
    #
    # FORMAT ISO 8601 : YYYY-MM-DDTHH:MM:SS
    # Exemple : "2018-03-15T14:30:00" = 15 mars 2018 Ã  14h30
    sim_time = datetime.fromisoformat(item['simulated_time'])
    
    # â”€â”€ Extraction du facteur de vitesse â”€â”€
    # DynamoDB renvoie les nombres en Decimal, on convertit en int
    # Le speed_factor dÃ©finit de combien de minutes on avance Ã  chaque exÃ©cution
    #
    # Exemples de valeurs courantes :
    # - 1 : Temps rÃ©el (1 min rÃ©elle = 1 min simulÃ©e)
    # - 60 : 1 heure simulÃ©e par exÃ©cution (24 exÃ©cutions = 1 jour)
    # - 1440 : 1 jour simulÃ© par exÃ©cution (365 exÃ©cutions = 1 an)
    speed = int(item['speed_factor'])
    
    return sim_time, speed


def update_simulation_time(current_time, minutes_to_add):
    """
    â±ï¸ FAIT AVANCER L'HORLOGE VIRTUELLE DE LA SIMULATION
    
    Cette fonction est appelÃ©e Ã  la FIN du lambda_handler(), aprÃ¨s avoir
    gÃ©nÃ©rÃ© toutes les commandes. Elle avance le temps virtuel de X minutes
    (oÃ¹ X = speed_factor, gÃ©nÃ©ralement 60).
    
    ğŸ”„ FLOW TEMPOREL DANS UNE EXÃ‰CUTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Lambda dÃ©marre
    2. get_simulation_state() â†’ RÃ©cupÃ¨re l'heure actuelle (ex: 14h00)
    3. GÃ©nÃ©ration de 5 commandes avec timestamp = 14h00
    4. update_simulation_time(14h00, 60) â†’ Avance Ã  15h00
    5. Lambda se termine
    6. Prochaine exÃ©cution repartira de 15h00
    
    ğŸ¯ PARAMÃˆTRES :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    current_time (datetime) : L'heure virtuelle AVANT mise Ã  jour
    minutes_to_add (int) : Nombre de minutes Ã  ajouter (= speed_factor)
    
    ğŸ”™ RETOUR :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    datetime : La nouvelle heure virtuelle APRÃˆS mise Ã  jour
    
    ğŸ”’ SÃ‰CURITÃ‰ : ATOMICITÃ‰ DE L'OPÃ‰RATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Cette fonction utilise UpdateExpression (syntaxe spÃ©cifique Ã  DynamoDB)
    au lieu de :
    1. Lire l'item
    2. Modifier en mÃ©moire
    3. RÃ©Ã©crire l'item
    
    POURQUOI ? Si 2 Lambdas s'exÃ©cutent en mÃªme temps (peu probable avec
    EventBridge Ã  1/min, mais thÃ©oriquement possible), on risquerait :
    - Lambda A lit : 14h00
    - Lambda B lit : 14h00
    - Lambda A Ã©crit : 15h00
    - Lambda B Ã©crit : 15h00 (Ã©crase A !)
    â†’ On avance de 1h au lieu de 2h !
    
    Avec UpdateExpression, DynamoDB garantit l'atomicitÃ© :
    - Lambda A update : 14h00 â†’ 15h00
    - Lambda B update : 15h00 â†’ 16h00
    â†’ CohÃ©rence garantie, mÃªme en concurrence
    
    ğŸ“ EXEMPLE D'EXÃ‰CUTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    current_time = datetime(2018, 3, 15, 14, 0)  # 15 mars 2018, 14h00
    minutes_to_add = 60
    
    Calcul : 2018-03-15 14:00:00 + 60 minutes = 2018-03-15 15:00:00
    
    DynamoDB aprÃ¨s update :
    {
      "config_key": "GLOBAL",
      "simulated_time": "2018-03-15T15:00:00",
      "speed_factor": 60
    }
    """
    
    # Connexion Ã  la table Config
    table = dynamodb.Table(TABLE_CONFIG)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CALCUL DE LA NOUVELLE HEURE VIRTUELLE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # timedelta = Objet Python reprÃ©sentant une durÃ©e
    # timedelta(minutes=60) = 1 heure
    # datetime + timedelta = nouvelle datetime
    #
    # Exemple :
    # datetime(2018, 3, 15, 14, 0) + timedelta(minutes=60) 
    # = datetime(2018, 3, 15, 15, 0)
    new_time = current_time + timedelta(minutes=minutes_to_add)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # MISE Ã€ JOUR ATOMIQUE DANS DYNAMODB
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # update_item() ne met Ã  jour QUE les attributs spÃ©cifiÃ©s
    # Contrairement Ã  put_item() qui remplace tout l'item
    #
    # SYNTAXE UPDATEEXPRESSION :
    # - "set" : opÃ©ration de modification
    # - "simulated_time = :t" : l'attribut Ã  modifier et sa nouvelle valeur
    # - ":t" : placeholder pour la valeur (dÃ©finie dans ExpressionAttributeValues)
    #
    # POURQUOI CETTE SYNTAXE ?
    # - SÃ©curitÃ© : EmpÃªche les injections SQL-like
    # - Performance : DynamoDB optimise les updates partiels
    # - AtomicitÃ© : L'opÃ©ration est atomique au niveau du service
    table.update_item(
        # Identifie l'item Ã  modifier (via sa clÃ© primaire)
        Key={'config_key': 'GLOBAL'},
        
        # Expression de mise Ã  jour (syntaxe DynamoDB)
        # "set X = :val" signifie "modifier l'attribut X avec la valeur :val"
        UpdateExpression="set simulated_time = :t",
        
        # Valeurs des placeholders utilisÃ©s dans UpdateExpression
        # :t sera remplacÃ© par new_time.isoformat()
        # 
        # .isoformat() convertit datetime en string ISO 8601
        # Exemple : datetime(2018, 3, 15, 15, 0).isoformat() = "2018-03-15T15:00:00"
        ExpressionAttributeValues={':t': new_time.isoformat()}
    )
    
    return new_time

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#              FONCTIONS DE GESTION DU CACHE PRODUITS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_products_once():
    """
    ğŸ“¦ CHARGE UNE LISTE DE PRODUCT_ID DEPUIS DYNAMODB DANS LE CACHE MÃ‰MOIRE
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ¯ OBJECTIF : Ã‰viter de scanner DynamoDB Ã  chaque commande    â”‚
    â”‚                                                                 â”‚
    â”‚  Sans cache :                                                   â”‚
    â”‚    Commande 1 â†’ Scan DynamoDB (2 sec, $$$)                     â”‚
    â”‚    Commande 2 â†’ Scan DynamoDB (2 sec, $$$)                     â”‚
    â”‚    Commande 3 â†’ Scan DynamoDB (2 sec, $$$)                     â”‚
    â”‚    ...                                                          â”‚
    â”‚                                                                 â”‚
    â”‚  Avec cache :                                                   â”‚
    â”‚    PremiÃ¨re exÃ©cution â†’ Scan DynamoDB (2 sec, $$$)             â”‚
    â”‚    Commande 1 â†’ Lecture cache (0.001 sec, GRATUIT)            â”‚
    â”‚    Commande 2 â†’ Lecture cache (0.001 sec, GRATUIT)            â”‚
    â”‚    ...                                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ—ï¸ ARCHITECTURE DU CACHE :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PRODUCT_CACHE (liste globale) :
    [
      "aca2eb7d0059a44648bf670b2a753042",
      "4244733e06e7ecb4970a6e2683c13e61",
      "d1c427060a0f73f6b889a5c7c61f2ac4",
      ...
    ]
    
    ğŸ“Š OPTIMISATIONS APPLIQUÃ‰ES :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. ProjectionExpression="product_id"
       â†’ On ne rÃ©cupÃ¨re QUE l'ID, pas les 10 autres attributs du produit
       â†’ RÃ©duit la taille du payload rÃ©seau de 90%
    
    2. Limit=500
       â†’ On limite Ã  500 produits au lieu des 32k du dataset complet
       â†’ Ã‰quilibre entre diversitÃ© et coÃ»t
       â†’ 500 produits = assez pour avoir de la variÃ©tÃ© dans les commandes
    
    3. VÃ©rification if PRODUCT_CACHE
       â†’ Si le cache est dÃ©jÃ  rempli, on ne rescanne pas
       â†’ Exploite la "chaleur" des Lambdas AWS
    
    ğŸ”¥ COMPORTEMENT "HOT vs COLD" DES LAMBDAS :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    AWS Lambda fonctionne avec des conteneurs rÃ©utilisables :
    
    COLD START (dÃ©marrage Ã  froid) :
    - La Lambda dÃ©marre pour la premiÃ¨re fois
    - PRODUCT_CACHE est vide â†’ load_products_once() fait un scan
    - DurÃ©e : ~2-3 secondes
    
    HOT EXECUTION (exÃ©cution Ã  chaud) :
    - AWS rÃ©utilise le mÃªme conteneur Lambda
    - PRODUCT_CACHE est dÃ©jÃ  rempli â†’ pas de scan
    - DurÃ©e : ~100-200 ms
    
    Si EventBridge exÃ©cute la Lambda toutes les minutes, elle reste
    quasiment toujours "chaude" â†’ le scan n'arrive qu'une fois par heure
    
    ğŸ’¡ AMÃ‰LIORATIONS POSSIBLES (HORS SCOPE) :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - Ajouter un TTL : recharger le cache toutes les 30 minutes
    - Utiliser ElastiCache Redis : cache partagÃ© entre toutes les Lambdas
    - Utiliser DynamoDB Streams : invalider le cache quand des produits changent
    - Stocker le cache dans S3 : prÃ©charger depuis S3 au lieu de scanner
    
    âš ï¸ ATTENTION : GLOBAL VARIABLE
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    On modifie PRODUCT_CACHE qui est une variable globale (dÃ©finie hors fonction).
    En Python, modifier une liste globale ne nÃ©cessite PAS le mot-clÃ© "global"
    (contrairement Ã  la rÃ©assignation). Mais pour la clartÃ©, on pourrait l'ajouter.
    """
    
    # AccÃ¨s Ã  la variable globale pour la modifier
    # Note : En Python, pour MODIFIER une liste globale, "global" n'est pas requis
    # Mais pour RÃ‰ASSIGNER (PRODUCT_CACHE = [...]), il faudrait "global PRODUCT_CACHE"
    global PRODUCT_CACHE
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # VÃ‰RIFICATION : LE CACHE EST-IL DÃ‰JÃ€ REMPLI ?
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Si PRODUCT_CACHE contient dÃ©jÃ  des donnÃ©es, on ne fait rien
    # 
    # Comportement :
    # - Liste vide [] Ã©value Ã  False en Python
    # - Liste avec Ã©lÃ©ments Ã©value Ã  True
    #
    # Exemple :
    # if []: print("vide")        â†’ s'exÃ©cute
    # if ["abc"]: print("plein")  â†’ s'exÃ©cute
    if PRODUCT_CACHE:
        # Le cache est dÃ©jÃ  chargÃ©, on ne fait rien
        # Cette ligne s'exÃ©cute sur TOUTES les exÃ©cutions "hot" de la Lambda
        return
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SCAN DE LA TABLE INVENTORY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Si on arrive ici, c'est que PRODUCT_CACHE est vide (premiÃ¨re exÃ©cution)
    
    # Connexion Ã  la table Inventory
    table = dynamodb.Table(TABLE_INVENTORY)
    
    # â”€â”€ SCAN vs QUERY vs GET_ITEM â”€â”€
    # 
    # GET_ITEM : RÃ©cupÃ¨re UN item par sa clÃ© primaire
    #   Usage : Quand on connaÃ®t l'ID exact
    #   CoÃ»t : 1 RCU (trÃ¨s rapide, trÃ¨s cheap)
    # 
    # QUERY : RÃ©cupÃ¨re des items par partition key (+ optional sort key)
    #   Usage : "Donne-moi tous les items du client X"
    #   CoÃ»t : Proportionnel au nombre d'items retournÃ©s
    # 
    # SCAN : Lit TOUTE la table, ligne par ligne
    #   Usage : Quand on ne sait pas quoi chercher prÃ©cisÃ©ment
    #   CoÃ»t : Lit TOUTE la table, mÃªme si on n'utilise que 500 items
    #   âš ï¸ OPÃ‰RATION COÃ›TEUSE ET LENTE
    # 
    # Ici, on DOIT utiliser scan() car on veut "des product_id au hasard"
    # sans critÃ¨re de recherche prÃ©cis.
    resp = table.scan(
        # â”€â”€ ProjectionExpression : Optimisation ClÃ© #1 â”€â”€
        # On ne rÃ©cupÃ¨re QUE l'attribut product_id
        # Sans Ã§a, DynamoDB renverrait TOUS les attributs :
        # - product_id
        # - stock_level
        # - category
        # - price
        # - product_weight_g
        # - etc.
        # 
        # Avec ProjectionExpression, on rÃ©duit le payload de ~90%
        # â†’ Moins de bande passante rÃ©seau
        # â†’ Moins de temps de transfert
        # â†’ Moins de RCU consommÃ©s
        ProjectionExpression="product_id",
        
        # â”€â”€ Limit : Optimisation ClÃ© #2 â”€â”€
        # On limite le scan Ã  500 items
        # Le dataset Olist original contient ~32 000 produits
        # 
        # Pourquoi 500 ?
        # - Assez pour avoir de la diversitÃ© dans les commandes gÃ©nÃ©rÃ©es
        # - Pas trop pour tenir facilement en mÃ©moire Lambda
        # - Balance entre coÃ»t et rÃ©alisme
        # 
        # En production, on augmenterait Ã  5000 ou 10000
        # Ou on utiliserait une approche plus sophistiquÃ©e (cache Redis)
        Limit=500
    )
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # EXTRACTION DES PRODUCT_ID ET STOCKAGE DANS LE CACHE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # resp['Items'] contient une liste de dictionnaires :
    # [
    #   {'product_id': 'aca2eb7d0059a44648bf670b2a753042'},
    #   {'product_id': '4244733e06e7ecb4970a6e2683c13e61'},
    #   ...
    # ]
    #
    # On extrait uniquement les valeurs de 'product_id' dans une liste simple
    # RÃ©sultat : ['aca2eb7d...', '4244733e...', ...]
    # 
    # List comprehension Python : [expression for item in list]
    # Ã‰quivalent Ã  :
    # PRODUCT_CACHE = []
    # for i in resp["Items"]:
    #     PRODUCT_CACHE.append(i["product_id"])
    PRODUCT_CACHE = [i["product_id"] for i in resp["Items"]]
    
    # Ã€ ce stade, PRODUCT_CACHE contient ~500 product_id
    # Les prochains appels Ã  load_products_once() ne feront rien (cache plein)


def get_random_product():
    """
    ğŸ² RETOURNE UN PRODUCT_ID ALÃ‰ATOIRE DEPUIS LE CACHE
    
    Cette fonction est appelÃ©e pour CHAQUE commande gÃ©nÃ©rÃ©e.
    Elle doit Ãªtre ULTRA RAPIDE car elle s'exÃ©cute des dizaines de fois
    par seconde en pÃ©riode de forte charge.
    
    ğŸ”„ FLOW D'EXÃ‰CUTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Appel de load_products_once()
       â†’ Si cache vide : charge depuis DynamoDB (LENT, 1Ã¨re fois seulement)
       â†’ Si cache plein : ne fait rien (RAPIDE, 99% du temps)
    
    2. SÃ©lection alÃ©atoire avec random.choice()
       â†’ ComplexitÃ© O(1), instantanÃ©
       â†’ Chaque produit a la mÃªme probabilitÃ© d'Ãªtre choisi
    
    3. Retour du product_id
       â†’ String de 32 caractÃ¨res hexadÃ©cimaux (hash MD5)
       â†’ Exemple : "aca2eb7d0059a44648bf670b2a753042"
    
    ğŸ¯ RETOUR :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    str : Un product_id valide, tirÃ© au hasard depuis le cache
    
    ğŸ“Š STATISTIQUES DE PERFORMANCE :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PremiÃ¨re exÃ©cution (COLD) :
    - load_products_once() â†’ scan DynamoDB â†’ 2000 ms
    - random.choice() â†’ 0.001 ms
    - TOTAL : ~2000 ms
    
    ExÃ©cutions suivantes (HOT) :
    - load_products_once() â†’ return immÃ©diat â†’ 0 ms
    - random.choice() â†’ 0.001 ms
    - TOTAL : ~0.001 ms (2 000 000x plus rapide !)
    
    ğŸ” ALTERNATIVE POUR PRODUCTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Dans une vraie application Ã  grande Ã©chelle, on pourrait :
    
    1. PrÃ©-gÃ©nÃ©rer une liste de 10k product_id et la stocker dans S3
    2. La Lambda tÃ©lÃ©charge cette liste au dÃ©marrage (1 fois)
    3. Plus besoin de scan DynamoDB du tout
    4. Ã‰conomie : ~$100/mois sur les RCU
    
    Ou encore mieux :
    1. Utiliser DynamoDB DAX (cache in-memory distribuÃ©)
    2. DAX cache automatiquement les rÃ©sultats de scan
    3. Latence : < 1 ms, mÃªme sur cold start
    4. CoÃ»t : ~$0.30/heure pour un nÅ“ud DAX
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 1 : REMPLIR LE CACHE (SI NÃ‰CESSAIRE)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Sur la premiÃ¨re exÃ©cution, cette fonction va :
    # 1. Scanner la table DynamoDB
    # 2. Remplir PRODUCT_CACHE avec ~500 product_id
    # 
    # Sur les exÃ©cutions suivantes (Lambda "hot"), elle ne fera rien
    load_products_once()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 2 : SÃ‰LECTION ALÃ‰ATOIRE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # random.choice(liste) retourne un Ã©lÃ©ment au hasard depuis la liste
    # 
    # DISTRIBUTION : Uniforme (chaque produit a la mÃªme probabilitÃ©)
    # Si PRODUCT_CACHE contient 500 items, chaque produit a 1/500 chance
    # 
    # PERFORMANCE : O(1) - instantanÃ©, mÃªme sur de grandes listes
    # Python utilise l'algorithme de Fisher-Yates sous le capot
    # 
    # COMPORTEMENT SI CACHE VIDE :
    # Si PRODUCT_CACHE = [], random.choice() lÃ¨vera une exception IndexError
    # En pratique, Ã§a ne devrait jamais arriver car load_products_once()
    # remplit toujours le cache (sauf si la table est vide, ce qui est un bug)
    return random.choice(PRODUCT_CACHE)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    HANDLER LAMBDA (POINT D'ENTRÃ‰E)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def lambda_handler(event, context):
    """
    ğŸš€ FONCTION PRINCIPALE DE LA LAMBDA - POINT D'ENTRÃ‰E AWS
    
    Cette fonction est appelÃ©e automatiquement par AWS Lambda lorsque :
    - EventBridge dÃ©clenche l'exÃ©cution (toutes les minutes)
    - Un utilisateur invoque manuellement la Lambda (pour tester)
    - Un autre service AWS appelle la Lambda (ex: API Gateway)
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ¯ MISSION : GÃ©nÃ©rer entre 3 et 20 commandes e-commerce        â”‚
    â”‚               conformes au format Olist et les envoyer          â”‚
    â”‚               vers Kinesis pour traitement en temps rÃ©el        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ“¥ PARAMÃˆTRES AWS LAMBDA :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    event (dict) : Contient les donnÃ©es d'entrÃ©e de l'invocation
                   Exemples :
                   - EventBridge : {} (vide, car rÃ¨gle schedule)
                   - API Gateway : {body, headers, queryStringParameters, ...}
                   - Test manuel : Tout JSON que vous passez
    
    context (LambdaContext) : Objet fourni par AWS avec des mÃ©tadonnÃ©es
                              - request_id : ID unique de cette exÃ©cution
                              - function_name : Nom de la Lambda
                              - memory_limit_in_mb : MÃ©moire allouÃ©e
                              - log_stream_name : Nom du stream CloudWatch Logs
                              - remaining_time_in_millis() : Temps avant timeout
    
    ğŸ”™ RETOUR :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dict : RÃ©ponse JSON standardisÃ©e (format API Gateway)
           {
             'statusCode': 200,
             'body': '{"message": "Success", "orders_count": 5}'
           }
    
    ğŸ—ï¸ ARCHITECTURE DE CETTE FONCTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. GET TIME      â”‚ â† RÃ©cupÃ¨re l'heure virtuelle depuis DynamoDB
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 2. GENERATE      â”‚ â† Boucle : gÃ©nÃ¨re 3-20 commandes
    â”‚    ORDERS        â”‚   Pour chaque commande :
    â”‚                  â”‚   a) Choisir un produit alÃ©atoire
    â”‚                  â”‚   b) DÃ©crÃ©menter le stock (transaction atomique)
    â”‚                  â”‚   c) CrÃ©er l'objet order (JSON)
    â”‚                  â”‚   d) Envoyer vers Kinesis
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. UPDATE TIME   â”‚ â† Avance l'horloge virtuelle de X minutes
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 4. RETURN        â”‚ â† Retourne le rÃ©sumÃ© (nombre de commandes, etc.)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ’° COÃ›TS AWS (ESTIMATION) :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Pour 1 exÃ©cution gÃ©nÃ©rant 10 commandes :
    - Lambda : $0.000000208 (128 MB, 500 ms)
    - DynamoDB reads : $0.0000025 (2 lectures, table Config et Inventory)
    - DynamoDB writes : $0.0000125 (10 dÃ©crÃ©ments de stock + 1 update Config)
    - Kinesis PUT : $0.000014 (10 records)
    - TOTAL : ~$0.000029 par exÃ©cution
    
    Sur 1 mois (43 200 exÃ©cutions Ã  1/min) : ~$1.25/mois
    â†’ SystÃ¨me ultra Ã©conomique !
    
    âš ï¸ POINTS D'ATTENTION :
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Gestion des erreurs : On utilise try/except pour chaque commande
       â†’ Si un produit est en rupture de stock, on passe au suivant
       â†’ La Lambda ne plante pas, elle log juste l'erreur
    
    2. AtomicitÃ© du stock : On utilise ConditionExpression
       â†’ EmpÃªche la survente (vendre un produit dÃ©jÃ  Ã  0)
       â†’ Si 2 Lambdas essaient de vendre le dernier item, 1 seule rÃ©ussit
    
    3. CohÃ©rence temporelle : TOUTES les commandes d'une exÃ©cution ont
       le MÃŠME timestamp (sim_time). CohÃ©rent avec le comportement rÃ©el
       oÃ¹ les commandes arrivent "en rafale" toutes les minutes.
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 1 : RÃ‰CUPÃ‰RATION DE L'Ã‰TAT DE LA SIMULATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # On rÃ©cupÃ¨re l'heure virtuelle actuelle et le facteur de vitesse
    # Exemple : sim_time = 2018-03-15 14:30:00, speed_factor = 60
    sim_time, speed_factor = get_simulation_state()
    
    # Liste pour tracker les order_id crÃ©Ã©s (pour logging et debugging)
    # Ã€ la fin, on pourra afficher "5 commandes crÃ©Ã©es : [id1, id2, ...]"
    orders_created = []
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # COMBIEN DE COMMANDES GÃ‰NÃ‰RER ?
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # On gÃ©nÃ¨re un nombre alÃ©atoire de commandes entre 3 et 20
    # 
    # POURQUOI CET INTERVALLE ?
    # - Minimum 3 : Pour simuler de l'activitÃ© mÃªme en pÃ©riode creuse
    # - Maximum 20 : Pour simuler des pics d'activitÃ© (soldes, Black Friday...)
    # 
    # Dans le dataset Olist rÃ©el :
    # - Moyenne : ~10 commandes/minute
    # - Pic : jusqu'Ã  50 commandes/minute (Black Friday)
    # - Creux : 1-2 commandes/minute (nuit, dimanche)
    # 
    # Pour un rÃ©alisme accru, on pourrait :
    # - Moduler selon l'heure : plus de commandes le soir que la nuit
    # - Moduler selon le jour : plus le vendredi que le dimanche
    # - Simuler des Ã©vÃ©nements : x10 pendant les soldes
    num_orders = random.randint(3, 20)
    
    # Connexion Ã  la table Inventory (pour dÃ©crÃ©menter le stock)
    table_inv = dynamodb.Table(TABLE_INVENTORY)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # LOG POUR CLOUDWATCH
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # print() dans une Lambda envoie automatiquement vers CloudWatch Logs
    # Utile pour :
    # - DÃ©bugger (voir ce qui se passe pendant l'exÃ©cution)
    # - Monitorer (nombre de commandes gÃ©nÃ©rÃ©es par exÃ©cution)
    # - Alerter (dÃ©tecter des anomalies)
    # 
    # Ce log apparaÃ®tra dans :
    # CloudWatch > Log groups > /aws/lambda/Olist-Order-Generator
    print(f"Simulation Time: {sim_time}, Generating {num_orders} orders")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 2 : BOUCLE DE GÃ‰NÃ‰RATION DES COMMANDES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # On itÃ¨re num_orders fois (ex: 10 fois si random.randint a renvoyÃ© 10)
    # Ã€ chaque itÃ©ration, on crÃ©e une commande complÃ¨te
    for _ in range(num_orders):
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ã‰TAPE 2.1 : SÃ‰LECTION D'UN PRODUIT ALÃ‰ATOIRE
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # get_random_product() pioche un product_id au hasard dans le cache
        # Exemple : "aca2eb7d0059a44648bf670b2a753042"
        product_id = get_random_product()
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ã‰TAPE 2.2 : DÃ‰CRÃ‰MENTATION ATOMIQUE DU STOCK
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # C'est la partie la plus critique du code.
        # On doit GARANTIR qu'on ne vend jamais un produit en rupture de stock.
        # 
        # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # â”‚  SCÃ‰NARIO PROBLÃ‰MATIQUE (SANS TRANSACTION ATOMIQUE) :        â”‚
        # â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        # â”‚  Stock initial : 1                                            â”‚
        # â”‚                                                               â”‚
        # â”‚  Lambda A lit stock : 1 âœ“                                     â”‚
        # â”‚  Lambda B lit stock : 1 âœ“                                     â”‚
        # â”‚  Lambda A vend : stock = 0 âœ“                                  â”‚
        # â”‚  Lambda B vend : stock = -1 âŒ SURVENTE !                     â”‚
        # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        # 
        # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # â”‚  SOLUTION : TRANSACTION ATOMIQUE AVEC CONDITION              â”‚
        # â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        # â”‚  Stock initial : 1                                            â”‚
        # â”‚                                                               â”‚
        # â”‚  Lambda A : update IF stock > 0 â†’ stock = 0 âœ“                â”‚
        # â”‚  Lambda B : update IF stock > 0 â†’ Ã‰CHEC âœ“                    â”‚
        # â”‚                                                               â”‚
        # â”‚  DynamoDB garantit qu'une seule des deux rÃ©ussira            â”‚
        # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        try:
            # â”€â”€ update_item() avec ConditionExpression â”€â”€
            # Cette opÃ©ration est ATOMIQUE : DynamoDB garantit que
            # si la condition est vÃ©rifiÃ©e au moment de l'Ã©criture,
            # l'update se fait. Sinon, une exception est levÃ©e.
            table_inv.update_item(
                # Identifie le produit Ã  modifier
                Key={'product_id': product_id},
                
                # â”€â”€ UpdateExpression : DÃ©crÃ©mente stock_level de 1 â”€â”€
                # "set X = X - :val" signifie "soustraire :val de X"
                # Ã‰quivalent Ã  : stock_level = stock_level - 1
                # 
                # ATTENTION : On ne peut PAS faire stock_level -= 1
                # DynamoDB requiert cette syntaxe spÃ©cifique
                UpdateExpression="set stock_level = stock_level - :val",
                
                # â”€â”€ ConditionExpression : VÃ©rifie stock > 0 AVANT d'Ã©crire â”€â”€
                # Cette condition est Ã©valuÃ©e par DynamoDB AVANT l'update
                # Si stock_level <= 0, l'update est ANNULÃ‰ et une exception
                # ConditionalCheckFailedException est levÃ©e
                # 
                # ":min": 0 signifie "stock doit Ãªtre > 0"
                # Si le stock est exactement 0, la condition Ã©choue
                ConditionExpression="stock_level > :min",
                
                # Valeurs des placeholders utilisÃ©s ci-dessus
                # :val = 1 â†’ on dÃ©crÃ©mente de 1
                # :min = 0 â†’ stock doit Ãªtre strictement positif
                ExpressionAttributeValues={':val': 1, ':min': 0}
            )
            
        except Exception as e:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # GESTION DE L'ERREUR : PRODUIT EN RUPTURE DE STOCK
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Si on arrive ici, c'est que :
            # 1. La ConditionExpression a Ã©chouÃ© (stock <= 0), OU
            # 2. Une autre erreur s'est produite (rÃ©seau, DynamoDB down...)
            # 
            # Dans les deux cas, on LOG l'erreur et on PASSE Ã€ LA
            # COMMANDE SUIVANTE (continue), au lieu de planter la Lambda.
            # 
            # Cela permet de gÃ©nÃ©rer les autres commandes mÃªme si un
            # produit particulier est en rupture.
            # 
            # EN PRODUCTION, on pourrait :
            # - Distinguer ConditionalCheckFailedException des autres erreurs
            # - Envoyer une alerte SNS si trop de ruptures de stock
            # - Retirer le produit du cache s'il est souvent en rupture
            print(f"Out of stock for {product_id}: {str(e)}")
            
            # continue = passe Ã  l'itÃ©ration suivante de la boucle for
            # La commande actuelle est abandonnÃ©e, on en gÃ©nÃ¨re une autre
            continue
        
        # Si on arrive ici, c'est que l'update a RÃ‰USSI :
        # - Le stock a bien Ã©tÃ© dÃ©crÃ©mentÃ©
        # - On peut crÃ©er la commande en toute sÃ©curitÃ©
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ã‰TAPE 2.3 : GÃ‰NÃ‰RATION DE L'OBJET COMMANDE (JSON)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # On crÃ©e un dictionnaire Python qui reprÃ©sente une commande Olist
        # Ce dictionnaire sera converti en JSON et envoyÃ© vers Kinesis
        
        # â”€â”€ GÃ©nÃ©ration de l'order_id unique â”€â”€
        # uuid.uuid4() gÃ©nÃ¨re un UUID version 4 (alÃ©atoire)
        # Exemple : "550e8400-e29b-41d4-a716-446655440000"
        # str() convertit l'objet UUID en string
        # 
        # UUID = Universally Unique IDentifier
        # ProbabilitÃ© de collision : 1 sur 2^122 (astronomiquement faible)
        # UtilisÃ© comme clÃ© primaire dans les bases de donnÃ©es distribuÃ©es
        order_id = str(uuid.uuid4())
        
        # â”€â”€ Construction du dictionnaire order â”€â”€
        order = {
            # â•â•â• ATTRIBUTS DE LA TABLE "ORDERS" (OLIST) â•â•â•
            
            # ID unique de la commande
            "order_id": order_id,
            
            # ID unique du client
            # Dans le vrai dataset Olist, il y a ~96k clients
            # Ici, on gÃ©nÃ¨re un nouvel UUID Ã  chaque commande
            # â†’ Simule des clients uniques (pas de clients rÃ©currents)
            # 
            # AMÃ‰LIORATION POSSIBLE :
            # - Avoir un pool de 10k customer_id dans un cache
            # - 20% des commandes proviennent de clients rÃ©currents
            # - 80% des commandes proviennent de nouveaux clients
            "customer_id": str(uuid.uuid4()),
            
            # Statut de la commande
            # Dans Olist, les statuts possibles sont :
            # - delivered (96%) : Commande livrÃ©e
            # - shipped (2%) : Commande expÃ©diÃ©e mais pas encore livrÃ©e
            # - canceled (1%) : Commande annulÃ©e
            # - processing, invoiced, unavailable, created (< 1%)
            # 
            # Ici, on met "approved" pour simplifier
            # EN PRODUCTION, on utiliserait random.choices() pour
            # avoir une distribution rÃ©aliste des statuts
            "order_status": "approved",
            
            # Timestamp de la commande (heure virtuelle)
            # .isoformat() convertit datetime en string ISO 8601
            # Exemple : "2018-03-15T14:30:00"
            # 
            # IMPORTANT : TOUTES les commandes de cette exÃ©cution
            # auront le MÃŠME timestamp (sim_time), car elles sont
            # considÃ©rÃ©es comme arrivÃ©es "en mÃªme temps" (dans la
            # mÃªme minute virtuelle)
            "order_purchase_timestamp": sim_time.isoformat(),
            
            # â•â•â• ATTRIBUTS DE LA TABLE "ORDER_ITEMS" (OLIST) â•â•â•
            # Dans le vrai dataset Olist, order_items est une table sÃ©parÃ©e
            # Ici, on l'imbrique dans "order" pour simplifier le traitement
            # 
            # "items" est une LISTE car une commande peut contenir
            # plusieurs produits. Ici, on ne simule qu'un seul produit
            # par commande pour simplifier.
            # 
            # AMÃ‰LIORATION POSSIBLE :
            # - 60% des commandes : 1 produit
            # - 30% des commandes : 2-3 produits
            # - 10% des commandes : 4-10 produits
            "items": [{
                # ID du produit achetÃ©
                "product_id": product_id,
                
                # Prix du produit (en BRL - Real BrÃ©silien)
                # random.uniform(20.0, 150.0) gÃ©nÃ¨re un float entre 20 et 150
                # float() convertit en float Python standard (DynamoDB n'aime pas Decimal ici)
                # 
                # Distribution des prix dans Olist rÃ©el :
                # - MÃ©diane : ~50 BRL (~10 USD)
                # - Moyenne : ~120 BRL (~25 USD)
                # - Max : ~6000 BRL (~1200 USD)
                # 
                # Notre intervalle 20-150 BRL simule des produits
                # de milieu de gamme (majoritaires sur Olist)
                "price": float(random.uniform(20.0, 150.0)),
                
                # Frais de port (freight = fret en franÃ§ais)
                # Dans Olist, les frais de port sont calculÃ©s selon :
                # - Le poids du produit
                # - La distance entre le vendeur et le client
                # - Le transporteur choisi
                # 
                # Intervalle 10-30 BRL reprÃ©sente des frais moyens
                # (Olist a une mÃ©diane de ~15 BRL)
                "freight_value": float(random.uniform(10.0, 30.0))
            }],
            
            # â•â•â• ATTRIBUTS DE LA TABLE "CUSTOMERS" (OLIST) â•â•â•
            # Dans le vrai dataset, customers est une table sÃ©parÃ©e
            # Ici, on l'imbrique pour simplifier
            "customer": {
                # Ville du client (gÃ©nÃ©rÃ©e par Faker avec locale pt_BR)
                # Exemples : "SÃ£o Paulo", "Rio de Janeiro", "Belo Horizonte"
                # Faker utilise une vraie liste de villes brÃ©siliennes
                "city": fake.city(),
                
                # Ã‰tat brÃ©silien (abrÃ©viation Ã  2 lettres)
                # Exemples : "SP" (SÃ£o Paulo), "RJ" (Rio de Janeiro), "MG" (Minas Gerais)
                # Le BrÃ©sil a 26 Ã©tats + 1 district fÃ©dÃ©ral
                # 
                # Distribution rÃ©elle Olist :
                # - SP : 42% (SÃ£o Paulo est le poumon Ã©conomique)
                # - RJ : 13%
                # - MG : 12%
                # - Autres : 33%
                "state": fake.state_abbr(),
                
                # Code postal brÃ©silien
                # Format : XXXXX-XXX (ex: "01310-100")
                # Faker gÃ©nÃ¨re des codes valides selon le format brÃ©silien
                "zip_code": fake.postcode()
            }
        }
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ã‰TAPE 2.4 : ENVOI DE LA COMMANDE VERS KINESIS
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Kinesis est un "tuyau" qui achemine les donnÃ©es en temps rÃ©el
        # vers leurs destinations (ici : Firehose â†’ S3)
        # 
        # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # â”‚  ARCHITECTURE DU FLUX DE DONNÃ‰ES :                         â”‚
        # â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        # â”‚  Lambda â†’ Kinesis Stream â†’ Firehose â†’ S3 â†’ Redshift       â”‚
        # â”‚                â†‘                                            â”‚
        # â”‚              ON EST ICI                                     â”‚
        # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        kinesis.put_record(
            # Nom du stream Kinesis (crÃ©Ã© manuellement dans la console)
            StreamName=STREAM_NAME,
            
            # â”€â”€ Data : Payload de l'Ã©vÃ©nement â”€â”€
            # Doit Ãªtre en bytes ou string
            # json.dumps() convertit le dict Python en string JSON
            # 
            # Exemple du rÃ©sultat :
            # '{"order_id":"550e8400-...","customer_id":"...", ...}'
            # 
            # Taille max d'un record Kinesis : 1 MB
            # Notre record fait ~500 bytes â†’ largement en dessous
            Data=json.dumps(order),
            
            # â”€â”€ PartitionKey : ClÃ© de partitionnement â”€â”€
            # Kinesis distribue les records sur plusieurs "shards"
            # selon le hash de la PartitionKey
            # 
            # RÃ¨gle : MÃªme PartitionKey â†’ MÃªme shard â†’ Ordre garanti
            # 
            # Ici, on utilise order_id comme clÃ©, donc chaque commande
            # va potentiellement sur un shard diffÃ©rent (rÃ©partition uniforme)
            # 
            # Si on voulait garantir l'ordre des commandes d'un mÃªme client,
            # on utiliserait customer_id comme PartitionKey
            PartitionKey=order_id
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TRACKING : Ajout de l'order_id Ã  la liste des commandes crÃ©Ã©es
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Cela nous permet de :
        # - Compter combien de commandes ont Ã©tÃ© gÃ©nÃ©rÃ©es
        # - Logger les IDs pour dÃ©boguer
        # - Retourner un rÃ©sumÃ© Ã  la fin de l'exÃ©cution
        orders_created.append(order_id)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 3 : AVANCEMENT DE L'HORLOGE VIRTUELLE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # On a fini de gÃ©nÃ©rer toutes les commandes pour cette exÃ©cution
    # Il faut maintenant avancer le temps virtuel pour que la prochaine
    # exÃ©cution parte de lÃ  oÃ¹ on s'est arrÃªtÃ©
    # 
    # Exemple :
    # - On Ã©tait Ã  2018-03-15 14:30:00
    # - speed_factor = 60
    # - Nouvel horaire : 2018-03-15 15:30:00
    # - Prochaine exÃ©cution (dans 1 min rÃ©elle) repartira de 15:30
    update_simulation_time(sim_time, speed_factor)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 4 : RETOUR DE LA RÃ‰PONSE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Une Lambda doit TOUJOURS retourner une rÃ©ponse
    # MÃªme si elle n'est pas utilisÃ©e (cas EventBridge), c'est une bonne pratique
    # 
    # Format standardisÃ© (compatible API Gateway) :
    # {
    #   'statusCode': 200,  # Code HTTP (200 = succÃ¨s, 500 = erreur)
    #   'body': '...'       # Payload en JSON (DOIT Ãªtre une string !)
    # }
    return {
        # Code de statut HTTP
        # 200 = OK, tout s'est bien passÃ©
        # Si on voulait signaler une erreur partielle, on pourrait utiliser 207 (Multi-Status)
        'statusCode': 200,
        
        # Corps de la rÃ©ponse (DOIT Ãªtre une string JSON)
        # On utilise un f-string pour construire un message informatif
        # 
        # len(orders_created) = nombre de commandes gÃ©nÃ©rÃ©es
        # sim_time = heure virtuelle actuelle
        # 
        # Exemple de body :
        # "Generated 12 orders. New Time: 2018-03-15 15:30:00"
        'body': json.dumps(f"Generated {len(orders_created)} orders. New Time: {sim_time}")
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                          FIN DU CODE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
ğŸ“ RÃ‰CAPITULATIF DES CONCEPTS CLÃ‰S :

1. TEMPS VIRTUEL
   - Permet d'accÃ©lÃ©rer la simulation
   - CohÃ©rence temporelle entre les exÃ©cutions
   - ReproductibilitÃ© des scÃ©narios

2. CACHE EN MÃ‰MOIRE
   - Ã‰vite les scans DynamoDB rÃ©pÃ©tÃ©s
   - Exploite la "chaleur" des Lambdas
   - Ã‰conomie de coÃ»ts et gain de performance

3. TRANSACTION ATOMIQUE
   - ConditionExpression empÃªche la survente
   - Garantit la cohÃ©rence du stock
   - Fonctionne mÃªme en concurrence

4. ARCHITECTURE EVENT-DRIVEN
   - Lambda = Stateless (pas de mÃ©moire entre exÃ©cutions)
   - DynamoDB = State store (stock, config)
   - Kinesis = Event bus (dÃ©couplage producteur/consommateur)

5. GÃ‰NÃ‰RATION DE DONNÃ‰ES RÃ‰ALISTES
   - Faker pour les donnÃ©es gÃ©ographiques
   - UUID pour les identifiants uniques
   - Random pour la variabilitÃ©

ğŸ“š POUR ALLER PLUS LOIN :
- Ajouter des seller_id (vendeurs) dans les commandes
- Simuler des commandes multi-produits
- ImplÃ©menter des patterns temporels (+ de commandes le soir)
- Ajouter des mÃ©triques CloudWatch custom
- ImplÃ©menter un systÃ¨me de retry en cas d'erreur Kinesis
"""